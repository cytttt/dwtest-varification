{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ref https://github.com/dima-quant/dwtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Durbin-Watson statistic and p-value.\n",
    "Free to use, copy, share, and modify.\n",
    "Implemented by Dmytro Makogon. Inspired by lmtest/R/dwtest.R\n",
    "\"\"\"\n",
    "from scipy.stats import norm\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "def dwtest(res, X, tail='both', method='Pan', matrix_inverse = False, n = 15):\n",
    "    \"\"\"\n",
    "    Calculate  Durbin-Watson statistic and p-value \n",
    "    References\n",
    "    ----------\n",
    "    J. Durbin and G. S. Watson (1950), \"Testing for Serial Correlation in Least\n",
    "    Squares Regression I\". Biometrika, Vol. 37, 409-428.\n",
    "    J. Durbin and G. S. Watson (1951), \"Testing for Serial Correlation in Least \n",
    "    Squares Regression: II\", Biometrika, Vol. 38, 159-177.\n",
    "    J. Durbin and G. S. Watson (1971), \"Testing for Serial Correlation in Least \n",
    "    Squares Regression: III\", Biometrika, Vol. 58, 1-19.\n",
    "    R. W. Farebrother (1980), \"Algorithm AS 153: Pan's Procedure for the Tail Probabilities\n",
    "    of the Durbin-Watson Statistic\", Journal of the Royal Statistical Society, Series C\n",
    "    (Applied Statistics), Vol. 29, 224-227.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res : ndarray (n_obs, 1)\n",
    "        Array of residuals\n",
    "    X : ndarray (n_obs, dim)\n",
    "        Array of regressors\n",
    "    tail : str\n",
    "        test 'left', 'right', or 'both' for two-sided\n",
    "    method : str  \n",
    "        Calculation method. 'Pan' for Pan's procedure and 'normal' for normal approximation\n",
    "    matrix_inverse : bool\n",
    "        Using matrix inverse is faster but less stable\n",
    "    n : int\n",
    "        Parameter of the gradsol function  \n",
    "    Returns\n",
    "    -------\n",
    "    p_val, DW : float64\n",
    "        p value and Durbin-Watson statistic \n",
    "    \"\"\"\n",
    "    if method=='Pan':\n",
    "        # use Pan's method\n",
    "        (p_right, DW) = dwtest_pan(res, X, matrix_inverse = matrix_inverse, n = n)\n",
    "        if (p_right<0) or (p_right>1):\n",
    "            # warning: Pan's method did not work\n",
    "            p_right = -1\n",
    "    elif method=='normal':\n",
    "        DW = dw_stat(res)\n",
    "        p_right = -1\n",
    "    else: \n",
    "        # error: no such method\n",
    "        pass \n",
    "        \n",
    "    \n",
    "    if (p_right<0):\n",
    "        # use normal approximation\n",
    "        (dw_mean, dw_var) = dw_meanvar(X, matrix_inverse = matrix_inverse)\n",
    "        p_right = norm.cdf((DW-dw_mean)/np.sqrt(dw_var))\n",
    "\n",
    "    if tail == 'both':\n",
    "        p_val = 2*min(p_right, 1 - p_right)\n",
    "    elif tail == 'right':\n",
    "        p_val = p_right\n",
    "    elif tail == 'left':\n",
    "        p_val = 1 - p_right\n",
    "    else:\n",
    "        pass # warning: no such test\n",
    "    return p_val, DW\n",
    "\n",
    "@jit(nopython=True, parallel=False)\n",
    "def dw_stat(res):\n",
    "    \"\"\"Calculate Durbin-Watson statistic\"\"\"\n",
    "    return np.sum(np.diff(res.T)**2) / np.sum(res**2)\n",
    "\n",
    "@jit(nopython=True, parallel=False)    \n",
    "def gradsol(x, a, m, n):\n",
    "    \"\"\"\n",
    "    Translated from FORTRAN to Python by Dima\n",
    "    -----------------------------------------\n",
    "    TRANSLATION OF AMENDED VERSION OF APPLIED STATISTICS ALGORITHM\n",
    "    AS 153 (AS R52), VOL. 33, 363-366, 1984.\n",
    "    BY R.W. FAREBROTHER  (ORIGINALLY NAMED GRADSOL OR PAN)\n",
    "    GRADSOL EVALUATES THE PROBABILITY THAT A WEIGHTED SUM OF\n",
    "    SQUARED STANDARD NORMAL VARIATES DIVIDED BY X TIMES THE UNWEIGHTED\n",
    "    SUM IS LESS THAN A GIVEN CONSTANT, I.E. THAT\n",
    "    A1.U1**2 + A2.U2**2 + ... + AM.UM**2 <\n",
    "    X*(U1**2 + U2**2 + ... + UM**2) + C\n",
    "    WHERE THE U'S ARE STANDARD NORMAL VARIABLES.\n",
    "    FOR THE DURBIN-WATSON STATISTIC, X = DW, AND\n",
    "    A ARE THE NON-ZERO EIGENVALUES OF THE \"M*A\" MATRIX.\n",
    "    \n",
    "    ORIGINALLY FROM STATLIB.  REVISED 5/3/1996 BY CLINT CUMMINS\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        The Durbin-Watson statistic\n",
    "    a : ndarray (m)\n",
    "        Sorted array of non-zero eigenvalues of MA matrix\n",
    "    m : int\n",
    "        Array size\n",
    "    n : int\n",
    "        The number of terms in the series, typically between 10 and 15\n",
    "    Returns\n",
    "    -------\n",
    "    sum0 : float64\n",
    "        p value \n",
    "    \"\"\"\n",
    "    nu = np.searchsorted(a, x, side = 'right')\n",
    "    # index starts from 0, a[nu-1] <= x < a[nu]\n",
    "    \n",
    "    if nu == m:\n",
    "        sum0 = 1.0\n",
    "    elif nu == 0:\n",
    "        sum0 = 0.0\n",
    "    else:\n",
    "        k = 1\n",
    "        h = m - nu\n",
    "    \n",
    "        if h >= nu:\n",
    "            d  = 2; h  = nu; k  = - k; \n",
    "            j1 = 0; j2 = 2; j3 = 3; j4 = 1\n",
    "        else:\n",
    "            d  = - 2; nu  = nu + 1; \n",
    "            j1 = m - 2; j2 = m - 1; j3 = m + 1; j4 = m\n",
    "    \n",
    "        pin = np.pi / (2*n)\n",
    "        sum0 = (k + 1) / 2\n",
    "        sgn0 = k / n\n",
    "        n2  = 2*n - 1\n",
    "    \n",
    "        # first integral\n",
    "        st = np.int32(h - 2*np.floor(h/2))\n",
    "        for  l1 in range(st, -1, -1):\n",
    "            # take into account that k = -np.sign(d)\n",
    "            for l2 in range(j2, nu-k, d): \n",
    "                sum1 = a[j4-1]\n",
    "                if l2 == 0:\n",
    "                    prod0 = x\n",
    "                else:\n",
    "                    # FIX BY CLINT CUMMINS 5/3/96\n",
    "                    # prod0 = a(j2)\n",
    "                    prod0 = a[l2-1] \n",
    "                u = 0.5*(sum1 + prod0)\n",
    "                v = 0.5*(sum1 - prod0)\n",
    "                sum1 = 0.0\n",
    "                for i in range(1,n2+2,2):\n",
    "                    y = u - v*np.cos(i*pin)\n",
    "                    num = y - x\n",
    "                    prod0 = np.prod(num / (y - a[:j1]))\n",
    "                    prod0 *= np.prod(num / (y - a[j3-1:]))\n",
    "                    sum1 += np.sqrt(np.abs(prod0))\n",
    "                sgn0 = -sgn0\n",
    "                sum0 += sgn0*sum1\n",
    "                j1 += d\n",
    "                j3 += d\n",
    "                j4 += d\n",
    "            # second integral\n",
    "            if d == 2:\n",
    "                j3 = j3 - 1\n",
    "            else:\n",
    "                j1 = j1 + 1 \n",
    "            j2 = 0\n",
    "            nu  = 0\n",
    "    return sum0\n",
    "\n",
    "@jit(nopython=True, parallel=False)\n",
    "def dwtest_pan(res, X, matrix_inverse = False, n = 15):\n",
    "    \"\"\"\n",
    "    Calculate  Durbin-Watson statistic according to\n",
    "    J. Durbin and G. S. Watson (1971), \"Testing for Serial Correlation in Least \n",
    "    Squares Regression: III\", Biometrika, Vol. 58, 1-19.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res : ndarray (n_obs, 1)\n",
    "        Array of residuals\n",
    "    X : ndarray (n_obs, dim)\n",
    "        Array of regressors\n",
    "    matrix_inverse : bool\n",
    "        Using matrix inverse is faster but less stable\n",
    "    n : int\n",
    "        Parameter of the gradsol function  \n",
    "    Returns\n",
    "    -------\n",
    "    p_right, DW : float64\n",
    "        Cumulative probability and Durbin-Watson statistic \n",
    "    \"\"\"\n",
    "    DW = dw_stat(res)\n",
    "    (n_obs, dim) = X.shape\n",
    "    \n",
    "    # construct A matrix\n",
    "    upp_one = np.diag(np.ones(n_obs-1),1)    \n",
    "    A =  2*np.eye(n_obs) - upp_one - upp_one.T   \n",
    "    A[0, 0] = 1\n",
    "    A[-1, -1] = 1\n",
    "    # calculate X(X'X)^{-1}X'\n",
    "    if matrix_inverse:\n",
    "        R = np.linalg.inv(np.dot(X.T, X))\n",
    "        QQt = np.dot(X.dot(R), X.T)\n",
    "    else:\n",
    "        # X = QR => QR (R'R)^-1 R'Q' = Q Q'\n",
    "        Qm = np.linalg.qr(X)[0]\n",
    "        QQt = Qm.dot(Qm.T)\n",
    "    # add identity to prevent insignificant imaginary values    \n",
    "    eigv = np.sort(np.real(np.linalg.eigvals(A - QQt.dot(A)+np.eye(n_obs))))-1\n",
    "    eigv = eigv[dim:]\n",
    "    eps = 1e-10\n",
    "    eigv = eigv[eigv > eps]\n",
    "    p_right = gradsol(DW, eigv, len(eigv), n)\n",
    "    return p_right, DW\n",
    "\n",
    "@jit(nopython=True, parallel=False)\n",
    "def dw_meanvar(X, matrix_inverse = False):\n",
    "    \"\"\"\n",
    "    Calculate mean and variance of Durbin-Watson statistic according to\n",
    "    J. Durbin and G. S. Watson (1950), \"Testing for Serial Correlation in Least\n",
    "    Squares Regression I\". Biometrika, 37, 409-428.\n",
    "    J. Durbin and G. S. Watson (1951), \"Testing for Serial Correlation in Least \n",
    "    Squares Regression: II\", Biometrika, Vol. 38, 159-177.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray (n_obs, dim)\n",
    "        Array of regressors\n",
    "    matrix_inverse : bool\n",
    "        Using matrix inverse is faster but less stable\n",
    "    Returns\n",
    "    -------\n",
    "    dw_mean, dw_var : float64\n",
    "        Mean and variance of Durbin-Watson statistic \n",
    "    \"\"\"\n",
    "    (n_obs, dim) = X.shape\n",
    "    AX = np.zeros(X.shape)\n",
    "    AX[0,:] = X[0,:] - X[1,:]\n",
    "    AX[-1,:] = X[-1,:] - X[-2,:]\n",
    "    AX[1:-1,:] = -X[:-2,:] + 2*X[1:-1,:] - X[2:,:]\n",
    "    if matrix_inverse:\n",
    "        AXR = AX.dot(np.linalg.inv(np.dot(X.T, X)))\n",
    "    else:\n",
    "        AXR = np.linalg.lstsq(np.dot(X.T, X), AX.T, rcond=-1)[0].T\n",
    "    B = np.dot(X.T, AXR)\n",
    "    P = 2*(n_obs - 1) - np.trace(B)\n",
    "    Q = 2*(3*n_obs - 4) - 2*np.trace(np.dot(AX.T, AXR)) + np.trace(B.dot(B))\n",
    "    dw_mean = P/(n_obs - dim)\n",
    "    dw_var = 2/((n_obs - dim)*(n_obs - dim + 2)) * (Q - P*dw_mean)\n",
    "    return dw_mean, dw_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .csv\n",
    " - Parameters:\n",
    "     - n : number of observations\n",
    "     - k : number of exogenous variables\n",
    "     - $\\rho$ : the scalar which we are going to test\n",
    "     - $\\sigma_{x}^2$ : variance of $x_i$ , default = 1\n",
    "     - $\\sigma_{\\beta}^2$ : variance of $\\beta_i$ , default = 1\n",
    "     - $\\sigma_{\\mu}^2$ : variance of $\\mu_i$ , default = 1\n",
    " - Variables:\n",
    "     - $x_i$     ~ $N(0,\\sigma_{x}^2)$, $i \\in n$\n",
    "     - $\\beta_j$ ~ $N(0,\\sigma_{\\beta}^2)$, $j \\in k$\n",
    "     - $\\mu_t$   ~ $N(0,\\sigma_{\\mu}^2)$, $t \\in n$\n",
    "     - $\\epsilon_t = \\rho \\times \\epsilon_{t-1}+\\mu_t$ , $\\epsilon_0 = \\mu_0$\n",
    "- Then we can calculate y frome parameters and variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is platform dependent! defult is for unix-like system! \n",
    "\"\"\"\n",
    "def generate_csv(n: int, k : int, rho: float, iterations :int, sigma_x = 1.0, sigma_beta = 1.0, sigma_mu = 1.0, maxfile = 100, platform = 'u'):\n",
    "    \"\"\"\n",
    "    maxfile : The number of .csv in the basis directory\n",
    "    \n",
    "    platform: A character('u', 'w') ,'u' for unix-like os such as Macos,Linus, 'w' for windows\n",
    "    \"\"\"\n",
    "    nd = iterations//maxfile + 1 if iterations%maxfile != 0 else iterations//maxfile # numbers of directories\n",
    "    ns  = str(n)+'_'+str(k)+'_'+str(rho)+'_'      # n_k_rho_\n",
    "    # ---------- platform dependent ---------- #\n",
    "    if platform == 'u':   # for unix-like\n",
    "        s = '/'\n",
    "    elif platform == 'w': # for windows\n",
    "        s = '\\\\'\n",
    "    # ------------ cd to test_ds ------------- #\n",
    "    if  not os.path.exists(\"test_ds\"):\n",
    "        os.mkdir(\"test_ds\")\n",
    "    os.chdir(\"test_ds\")\n",
    "    # ---------------------------------------- #\n",
    "    os.mkdir(str(n)+'_'+str(k)+'_'+str(rho))\n",
    "    os.chdir(str(n)+'_'+str(k)+'_'+str(rho))\n",
    "    for i in range(nd):\n",
    "        os.mkdir(ns+str(i+1))\n",
    "        os.chdir(ns+str(i+1))\n",
    "        for j in range( iterations%maxfile if i == nd-1 and iterations%maxfile != 0 else maxfile):\n",
    "            head     = [ \"y\" if i == k+1 else\"x\"+str(i) for i in range(1,k+2)]   # x1, x2, x3... y\n",
    "            tmp_x    = np.random.normal(0,sigma_x,np.array((n,k)))\n",
    "            tmp_beta = np.random.normal(0,sigma_beta,np.array((k,1)))          # beta_1, beta_2...\n",
    "            tmp_mu   = np.random.normal(0,sigma_mu,np.array((n+1,1)))          # n+1\n",
    "            epsilon  = np.array([ rho*tmp_mu[i]+tmp_mu[i+1] for i in range(len(tmp_mu)-1) ])\n",
    "            beta_0   = np.random.normal(0,sigma_beta) \n",
    "            y = np.dot(tmp_x,tmp_beta)+beta_0+epsilon\n",
    "            tmp_data = np.hstack((tmp_x,y))\n",
    "            tmp_df = pd.DataFrame(tmp_data,columns = head)\n",
    "            tmp_df.to_csv( ns+str(i+1)+'_'+str(j+1+maxfile*i)+\".csv\" ,mode = 'a',header = True,index = False)\n",
    "        os.chdir(\"..\"+s)\n",
    "    os.chdir(\"..\"+s)\n",
    "    os.chdir(\"..\"+s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = [10,20,50,100,200,500,1000]\n",
    "klist = [1,2,3,5,10]\n",
    "rholist = [0,0.1,0.3,0.5]\n",
    "it = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nlist:\n",
    "    for j in klist:\n",
    "        for k in rholist:\n",
    "            generate_csv(i,j,k,it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/choyt/Documents/statistics_II/bonus'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Output .csv each contains the resulting p value for right, two, left tailed dwtest for given n,k,rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_dwtest(n: int, k : int, rho: float, iterations :int, maxfile = 100, platform = 'u'):\n",
    "    pvals_r = []\n",
    "    pvals_t = []\n",
    "    pvals_l = []\n",
    "    #timerecord = []\n",
    "    nd = iterations//maxfile + 1 if iterations%maxfile != 0 else iterations//maxfile # numbers of directories\n",
    "    ns  = str(n)+'_'+str(k)+'_'+str(rho)+'_'      # n_k_rho_\n",
    "    # ---------- platform dependent ---------- #\n",
    "    if platform == 'u':   # for unix-like\n",
    "        s = '/'\n",
    "    elif platform == 'w': # for windows\n",
    "        s = '\\\\'\n",
    "    # ---------------------------------------- #\n",
    "    os.chdir(\"test_ds\")\n",
    "    os.chdir(str(n)+'_'+str(k)+'_'+str(rho))\n",
    "    # ---------------------------------------- #\n",
    "    formula = \"y ~ \"\n",
    "    for i in range(k):\n",
    "        formula = formula + \"x\"+str(i+1)\n",
    "        if i != k-1:\n",
    "            formula = formula + \" + \"\n",
    "    # ---------------------------------------- #\n",
    "    for i in range(nd):\n",
    "        os.chdir(ns+str(i+1))\n",
    "        for j in range( iterations%maxfile if i == nd-1 and iterations%maxfile != 0 else maxfile):\n",
    "            df = pd.read_csv(ns+str(i+1)+'_'+str(j+1+maxfile*i)+\".csv\")\n",
    "            # ------------------------\n",
    "            dfmodel = smf.ols(formula,data = df)\n",
    "            if n < 3:\n",
    "                warnings.warn(\"not enough observations for computing a p value\")\n",
    "            elif n >= 3 and n < 100:\n",
    "                try:\n",
    "                    pvals_r.append(dwtest(dfmodel.fit().resid_pearson.reshape((n,1)),dfmodel.exog,\"right\",\"Pan\")[0])\n",
    "                except ValueError:\n",
    "                    pvals_r.append(np.nan)\n",
    "                try:\n",
    "                    pvals_t.append(dwtest(dfmodel.fit().resid_pearson.reshape((n,1)),dfmodel.exog,\"both\",\"Pan\")[0])\n",
    "                except ValueError:\n",
    "                    pvals_t.append(np.nan)\n",
    "                try:\n",
    "                    pvals_l.append(dwtest(dfmodel.fit().resid_pearson.reshape((n,1)),dfmodel.exog,\"left\",\"Pan\")[0])\n",
    "                except ValueError:\n",
    "                    pvals_l.append(np.nan)\n",
    "            else:\n",
    "                #start = timeit.default_timer()\n",
    "\n",
    "                try:\n",
    "                    pvals_r.append(dwtest(dfmodel.fit().resid_pearson.reshape((n,1)),dfmodel.exog,\"right\",\"normal\")[0])\n",
    "                except ValueError:\n",
    "                    pvals_r.append(np.nan)\n",
    "                try:\n",
    "                    pvals_t.append(dwtest(dfmodel.fit().resid_pearson.reshape((n,1)),dfmodel.exog,\"both\",\"normal\")[0])\n",
    "                except ValueError:\n",
    "                    pvals_t.append(np.nan)\n",
    "                try:\n",
    "                    pvals_l.append(dwtest(dfmodel.fit().resid_pearson.reshape((n,1)),dfmodel.exog,\"left\",\"normal\")[0])\n",
    "                except ValueError:\n",
    "                    pvals_l.append(np.nan)\n",
    "\n",
    "                #stop = timeit.default_timer()\n",
    "                #timerecord.append(stop-start)\n",
    "\n",
    "            # ------------------------\n",
    "            # pval = dwtest(formula,df, alternative = at)[1]\n",
    "            # pvals.append(pval)\n",
    "            # ------------------------\n",
    "        os.chdir(\"..\"+s)\n",
    "    os.chdir(\"..\"+s)\n",
    "    os.chdir(\"..\"+s)\n",
    "    # ---------------------------------------- #\n",
    "    if  not os.path.exists(\"pyresult_ds\"):\n",
    "        os.mkdir(\"pyresult_ds\")\n",
    "    os.chdir(\"pyresult_ds\")\n",
    "    dftmp = pd.DataFrame(list(zip(pvals_r, pvals_t, pvals_l)),\n",
    "             columns=['pval'+ns+i for i in ['r','t','l']])\n",
    "    dftmp.to_csv( \"py_pval\"+str(n)+'_'+str(k)+'_'+str(rho)+\".csv\" ,mode = 'a',header = True,index = False)\n",
    "    os.chdir(\"..\"+s)\n",
    "    # ---------------------------------------- #\n",
    "    #return timerecord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = [10,20,50,100,200,500,1000]\n",
    "klist = [1,2,3,5,10]\n",
    "rholist = [0,0.1,0.3,0.5]\n",
    "it = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test the dwtest and output .csv which record p value of each data\n",
    "\n",
    "for i in nlist:\n",
    "    for j in klist:\n",
    "        if i == j:\n",
    "            continue\n",
    "        for k in rholist:\n",
    "            test_dwtest(i,j,k,it)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing while test the speed of dwtest\n",
    "need to enable line 6, 46, 61, 62, 65, 66, 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the mean of execution time\n",
    "\n",
    "pnlist = [100,200,500,1000]\n",
    "\n",
    "for i in pnlist:\n",
    "    for j in klist:\n",
    "        for k in rholist:\n",
    "            tr = test_dwtest(i,j,k,it)\n",
    "            mtr.append(sum(tr)/len(tr))\n",
    "dftmp = pd.DataFrame(mtr,\n",
    "        columns=[\"mean\"])\n",
    "dftmp.to_csv( \"meantime.csv\" ,mode = 'a',header = True,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
